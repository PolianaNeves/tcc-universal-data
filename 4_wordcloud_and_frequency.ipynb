{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_wordcloud_and_frequency.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1HbyGw8gEd9tXsamdKBmbFUJX7JNJaGUt","authorship_tag":"ABX9TyNkr6N6NZmRpaBjqL0UlBcb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"U4Y-ZCOxfM9c"},"source":["# Gerando o dataset com as frequências e a nuvem de palavras (wordcloud)\n","\n","Ambos podem ser gerados pelo dashboard, mas achei menos complexo e de melhor visualização colocar algo estático no dashboard"]},{"cell_type":"markdown","metadata":{"id":"SelhQZ5ay-Gg"},"source":["[Frequency](https://amueller.github.io/word_cloud/auto_examples/frequency.html)\n","[WordCloud code](https://amueller.github.io/word_cloud/auto_examples/frequency.html)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"61arHQ1IhPmo","executionInfo":{"status":"ok","timestamp":1638482264171,"user_tz":180,"elapsed":2829,"user":{"displayName":"Poliana Ambrosio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcjWY2eshKldF2xD9hFuRnHqXR0-Ir3TD2G0P2XA=s64","userId":"17769152460747183137"}},"outputId":"c50cb8a9-98d5-433b-e235-dfd1ee8b7e55"},"source":["!pip install multidict"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: multidict in /usr/local/lib/python3.7/dist-packages (5.2.0)\n"]}]},{"cell_type":"code","metadata":{"id":"lWNbRQtGzuhc"},"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import numpy as np\n","from wordcloud import WordCloud"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RkXd0asGfz_o"},"source":["Por uma decisão de negócio, os datasets serão separados em avaliações positivas e negativas, para ficar de melhor visualização aos gestores."]},{"cell_type":"code","metadata":{"id":"NTtiHkSpz0GZ"},"source":["#Importando e sepanrando os datasets\n","df_reviews = pd.read_csv(\"drive/My Drive/Colab Notebooks/TCC/dataset_completed.csv\")\n","df_negative_reviews = df_reviews.loc[df_reviews['label'] == 0]\n","df_positive_reviews = df_reviews.loc[df_reviews['label'] == 1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PhNuNf_O2FVl"},"source":["[TfidVectorizer](https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html)\n","[TfidVectorizer Docs](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"]},{"cell_type":"code","metadata":{"id":"ClbNPXdthUXb"},"source":["def get_terms_frequencies(dataset, top_n):\n","    \"\"\"Retorna um dict com os termos mais frequentes, que serão usados então para\n","    gerar a wordcloud.\"\"\"    \n","    \n","    \"\"\"\"Tomei a decisão de remover algumas palavras que seriam irrelevantes para o\n","    modelo, considerando o contexto\"\"\"\"\n","    stop_words = [\"universal\", \"ride\", \"studios\", \"park\", \"day\", \"year\", \"month\", \"time\",\n","                  \"great\", \"good\", \"bad\", \"worst\", \"like\"]\n","\n","    #Inicia o TFIDF e treina o modelo com base nos tokens\n","    vectorizer_train = TfidfVectorizer(ngram_range=(1,1), strip_accents='ascii', stop_words=stop_words)\n","    train_vectors = vectorizer_train.fit_transform(dataset[\"tokens\"])\n","    \n","    #Extrai e retorna as features e os pesos\n","    indices = np.argsort(vectorizer_train.idf_)[::-1]\n","    features = vectorizer_train.get_feature_names_out()\n","    top_n = top_n\n","    top_features = [features[i] for i in indices[-top_n:]]\n","    top_idf = [vectorizer_train.idf_[i] for i in indices[-top_n:]]\n","    top_idf.sort(reverse=False)\n","\n","    frequencies_and_terms = zip(top_features, top_idf)\n","    frequencies_dict = dict(frequencies_and_terms)\n","\n","    return frequencies_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XbfnKSOM5-2s"},"source":["#Divide as frequencias entre os datasets.\n","positive_frequency_dict = get_terms_frequencies(df_positive_reviews, 100)\n","negative_frequency_dict = get_terms_frequencies(df_negative_reviews, 100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zm0OX2wXLwOB","executionInfo":{"status":"ok","timestamp":1638482272119,"user_tz":180,"elapsed":4190,"user":{"displayName":"Poliana Ambrosio","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcjWY2eshKldF2xD9hFuRnHqXR0-Ir3TD2G0P2XA=s64","userId":"17769152460747183137"}},"outputId":"6fd61f8a-35b5-45de-a90a-18b7493e2884"},"source":["#Gera as wordclouds positivas e negativas\n","positive_wc = WordCloud(background_color=\"black\", width=1000,height=1000, max_words=100).generate_from_frequencies(positive_frequency_dict)\n","positive_wc.to_file(\"drive/My Drive/Colab Notebooks/TCC/positive_wordcloud.jpg\")\n","\n","negative_wc = WordCloud(background_color=\"black\", width=1000,height=1000, max_words=100).generate_from_frequencies(negative_frequency_dict)\n","negative_wc.to_file(\"drive/My Drive/Colab Notebooks/TCC/negative_wordcloud.jpg\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<wordcloud.wordcloud.WordCloud at 0x7f2306f9e1d0>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"Ixf9x_OoEfgp"},"source":["#Cria um dataframe com os termos e frequências gerados\n","df_positive_frequencies = pd.DataFrame.from_dict([positive_frequency_dict]).T.rename(columns={0:'frequency'}, inplace=False)\n","df_negative_frequencies = pd.DataFrame.from_dict([negative_frequency_dict]).T.rename(columns={0:'frequency'}, inplace=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JdSAUdusMn1b"},"source":["#Salva o resultado dos dataframes em um dataset\n","df_positive_frequencies.to_csv(\"drive/My Drive/Colab Notebooks/TCC/positive_frequencies.csv\")\n","df_positive_frequencies.to_csv(\"drive/My Drive/Colab Notebooks/TCC/negative_frequencies.csv\")"],"execution_count":null,"outputs":[]}]}